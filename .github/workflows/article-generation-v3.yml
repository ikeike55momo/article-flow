name: Article Generation V3 (MCP + Imagen4)

on:
  workflow_dispatch:
    inputs:
      article_title:
        description: '記事タイトル'
        required: true
        type: string
        default: ''
      
      target_persona:
        description: 'ターゲットペルソナ（例：30代女性、健康意識が高い、子育て中）'
        required: true
        type: string
        default: ''
      
      meta_keywords:
        description: 'メタキーワード（カンマ区切り）'
        required: true
        type: string
        default: ''
      
      enable_image_generation:
        description: '画像生成を有効にする'
        required: false
        type: boolean
        default: true
      
      enable_drive_upload:
        description: 'Google Driveへのアップロード'
        required: false
        type: boolean
        default: false

env:
  PYTHON_VERSION: '3.11'

jobs:
  # ジョブ1: 初期化
  initialize:
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 5
    outputs:
      article_id: ${{ steps.init.outputs.article_id }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize article generation
        id: init
        run: |
          # タイトルからIDを生成
          CLEAN_TITLE=$(echo "${{ inputs.article_title }}" | sed 's/[^a-zA-Z0-9あ-んア-ン一-龯]/_/g' | cut -c1-50)
          ARTICLE_ID=$(date +%Y%m%d_%H%M%S)_${CLEAN_TITLE}
          echo "article_id=${ARTICLE_ID}" >> $GITHUB_OUTPUT
          echo "Article ID: ${ARTICLE_ID}"
          
          # 出力ディレクトリ作成
          mkdir -p output/${ARTICLE_ID}
          
          # 入力情報を保存
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          cat > output/${ARTICLE_ID}/input_params.json << EOJSON
          {
            "article_id": "${ARTICLE_ID}",
            "title": "${{ inputs.article_title }}",
            "target_persona": "${{ inputs.target_persona }}",
            "meta_keywords": "${{ inputs.meta_keywords }}",
            "created_at": "${TIMESTAMP}"
          }
          EOJSON

      - name: Upload initialization artifacts
        uses: actions/upload-artifact@v4
        with:
          name: init-${{ steps.init.outputs.article_id }}
          path: output/${{ steps.init.outputs.article_id }}
          retention-days: 30

  # ジョブ2: リクエスト分析
  analysis:
    needs: initialize
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 10
    outputs:
      main_keyword: ${{ steps.analyze.outputs.main_keyword }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download initialization artifacts
        uses: actions/download-artifact@v4
        with:
          name: init-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          cd github-actions
          pip install -r requirements.txt

      - name: Create analysis input
        run: |
          cd output/${{ needs.initialize.outputs.article_id }}
          # Phase1が期待する形式のJSONを作成
          cat > request_params.json << EOJSON
          {
            "topic": "${{ inputs.article_title }}",
            "target_audience": "${{ inputs.target_persona }}",
            "keywords": "${{ inputs.meta_keywords }}"
          }
          EOJSON

      - name: Run Phase 1 Analysis with Claude
        uses: anthropics/claude-code-base-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          
          prompt: |
            記事リクエストを分析して、SEO最適化された記事生成のための詳細パラメータを抽出してください。
            
            入力情報:
            - トピック: ${{ inputs.article_title }}  
            - ターゲット読者: ${{ inputs.target_persona }}
            - メタキーワード: ${{ inputs.meta_keywords }}
            
            タスク:
            1. request_params.json を読み込んで理解
            2. 以下の分析を実行:
               - メインキーワードの特定
               - 関連キーワードの抽出（5-8個）
               - 検索意図の分析
               - リサーチクエリの生成（15-25個）
            
            3. 分析結果をphase1_output.jsonファイルに保存してください
            
            重要：以下の形式でanalysisオブジェクトを含むJSONを作成してください：
            {
              "analysis": {
                "main_keyword": "抽出したメインキーワード",
                "related_keywords": ["関連1", "関連2", "関連3", "関連4", "関連5"],
                "search_intent": "informational",
                "content_type": "how-to", 
                "tone": "friendly",
                "key_points": ["ポイント1", "ポイント2", "ポイント3"],
                "research_queries": ["クエリ1", "クエリ2", "クエリ3", "クエリ4", "クエリ5", "クエリ6", "クエリ7", "クエリ8", "クエリ9", "クエリ10", "クエリ11", "クエリ12", "クエリ13", "クエリ14", "クエリ15"],
                "competitor_analysis_needed": true,
                "local_seo_focus": false,
                "estimated_sections": 5
              },
              "topic": "${{ inputs.article_title }}",
              "target_audience": "${{ inputs.target_persona }}",
              "keywords": "${{ inputs.meta_keywords }}",
              "processed_at": "現在時刻",
              "workflow_version": "3.0.0"
            }
          
          allowed_tools: |
            Read,
            Write
          
          claude_env: |
            ARTICLE_ID=${{ needs.initialize.outputs.article_id }}
          
          max_turns: "5"
      
      - name: Verify and prepare analysis results
        run: |
          cd output/${{ needs.initialize.outputs.article_id }}
          if [ -f "phase1_output.json" ]; then
            echo "✅ Phase 1 analysis file found"
            cat phase1_output.json
          else
            echo "⚠️ Phase 1 analysis file not found, creating default"
            # Create fallback analysis if Claude didn't create the file
            TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
            TITLE="${{ inputs.article_title }}"
            PERSONA="${{ inputs.target_persona }}"
            KEYWORDS="${{ inputs.meta_keywords }}"
            
            cat > phase1_output.json << EOF
{
  "analysis": {
    "main_keyword": "${TITLE}",
    "related_keywords": ["${KEYWORDS}", "健康", "美容", "セルフケア", "効果"],
    "search_intent": "informational",
    "content_type": "how-to",
    "tone": "friendly", 
    "key_points": ["基本情報", "実践方法", "注意点"],
    "research_queries": [
      "${TITLE} とは",
      "${TITLE} 方法", 
      "${TITLE} 効果",
      "${TITLE} 注意点",
      "${TITLE} おすすめ",
      "${TITLE} 初心者",
      "${TITLE} やり方",
      "${TITLE} コツ",
      "${TITLE} 失敗",
      "${TITLE} 安全",
      "${TITLE} 専門家",
      "${TITLE} 研究",
      "${TITLE} 統計",
      "${TITLE} 2024",
      "${TITLE} 最新"
    ],
    "competitor_analysis_needed": true,
    "local_seo_focus": false,
    "estimated_sections": 5
  },
  "topic": "${TITLE}",
  "target_audience": "${PERSONA}",
  "keywords": "${KEYWORDS}",
  "processed_at": "${TIMESTAMP}",
  "workflow_version": "3.0.0"
}
EOF
          fi

      - name: Split research queries into batches
        id: analyze
        run: |
          # クエリを5バッチに分割
          cd output/${{ needs.initialize.outputs.article_id }}
          python3 -c "
import json
import math

# 分析結果を読み込み
with open('phase1_output.json', 'r') as f:
    data = json.load(f)

queries = data.get('analysis', {}).get('research_queries', [])
total_queries = len(queries)
batch_size = math.ceil(total_queries / 5)

# 各バッチのクエリを保存
for i in range(5):
    start_idx = i * batch_size
    end_idx = min((i + 1) * batch_size, total_queries)
    batch_queries = queries[start_idx:end_idx]
    
    batch_data = {
        'batch_id': i,
        'queries': batch_queries,
        'total_batches': 5
    }
    
    with open(f'research_batch_{i}.json', 'w') as f:
        json.dump(batch_data, f, ensure_ascii=False, indent=2)

# メタ情報を保存
meta = {
    'total_queries': total_queries,
    'batch_count': 5,
    'batch_size': batch_size,
    'main_keyword': data.get('analysis', {}).get('main_keyword', '')
}
with open('research_meta.json', 'w') as f:
    json.dump(meta, f, ensure_ascii=False, indent=2)
"
          
          # メインキーワードを出力
          if [ -f "research_meta.json" ]; then
            MAIN_KW=$(python -c "import json; print(json.load(open('research_meta.json'))['main_keyword'])")
            echo "main_keyword=${MAIN_KW}" >> $GITHUB_OUTPUT
          fi
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          ENABLE_GEMINI_RESEARCH: "true"

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        with:
          name: analysis-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}
          retention-days: 30

  # ジョブ3: リサーチ（Gemini使用 - 並列実行）
  research:
    needs: [initialize, analysis]
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 15
    strategy:
      matrix:
        batch: [0, 1, 2, 3, 4]
      max-parallel: 5
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download initialization artifacts
        uses: actions/download-artifact@v4
        with:
          name: init-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          cd github-actions
          pip install -r requirements.txt

      - name: Research with Gemini (Batch ${{ matrix.batch }})
        run: |
          cd output/${{ needs.initialize.outputs.article_id }}
          
          # バッチ用の分析ファイルを作成
          BATCH_NUM=${{ matrix.batch }}
          python3 -c "
import json

# オリジナルの分析結果を読み込み
with open('phase1_output.json', 'r') as f:
    original_data = json.load(f)

# このバッチのクエリを読み込み
with open('research_batch_${BATCH_NUM}.json', 'r') as f:
    batch_data = json.load(f)

# バッチ用の分析ファイルを作成
batch_analysis = original_data.copy()
batch_analysis['analysis']['research_queries'] = batch_data['queries']

with open('batch_${BATCH_NUM}_analysis.json', 'w') as f:
    json.dump(batch_analysis, f, ensure_ascii=False, indent=2)
"
          
          cd ../../github-actions
          python scripts/phase2_research_gemini.py \
            --params-file ../output/${{ needs.initialize.outputs.article_id }}/batch_${{ matrix.batch }}_analysis.json \
            --output-dir ../output/${{ needs.initialize.outputs.article_id }}/batch_${{ matrix.batch }}
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

      - name: Upload research batch artifacts
        uses: actions/upload-artifact@v4
        with:
          name: research-batch-${{ matrix.batch }}-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}/batch_${{ matrix.batch }}
          retention-days: 30

  # ジョブ4: リサーチ結果の統合
  research-merge:
    needs: [initialize, research]
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 10
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create output directory
        run: mkdir -p output/${{ needs.initialize.outputs.article_id }}

      - name: Download all research batches
        uses: actions/download-artifact@v4
        with:
          pattern: research-batch-*-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}/batches

      - name: Download analysis artifacts
        uses: actions/download-artifact@v4
        with:
          name: analysis-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}

      - name: Merge research results
        run: |
          cd output/${{ needs.initialize.outputs.article_id }}
          
          # リサーチ結果を統合
          python3 -c "
import json
import os
from pathlib import Path
from datetime import datetime

# 全バッチの結果を収集
all_results = []
all_sources = []
all_key_findings = []

# バッチディレクトリを探索
batch_dirs = sorted(Path('batches').glob('research-batch-*'))

for batch_dir in batch_dirs:
    # 各バッチのphase2_research.jsonを読み込み
    research_file = batch_dir / 'phase2_research.json'
    if research_file.exists():
        with open(research_file, 'r') as f:
            batch_data = json.load(f)
            
            # 結果を統合
            if 'results' in batch_data:
                all_results.extend(batch_data['results'])
            if 'sources' in batch_data:
                all_sources.extend(batch_data['sources'])
            if 'key_findings' in batch_data:
                all_key_findings.extend(batch_data['key_findings'])

# 統合された結果を保存
merged_research = {
    'results': all_results,
    'sources': list(set(all_sources)),  # 重複を除去
    'key_findings': all_key_findings,
    'total_queries': len(all_results),
    'timestamp': str(datetime.now())
}

with open('phase2_research.json', 'w') as f:
    json.dump(merged_research, f, ensure_ascii=False, indent=2)

print(f'Merged {len(batch_dirs)} batches with {len(all_results)} total results')
"

      - name: Upload merged research artifacts
        uses: actions/upload-artifact@v4
        with:
          name: research-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}
          retention-days: 30

  # ジョブ5: 記事構成の生成
  generate-structure:
    needs: [initialize, analysis, research-merge]
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 15
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-${{ needs.initialize.outputs.article_id }}'
          path: output/${{ needs.initialize.outputs.article_id }}
          merge-multiple: true

      - name: Generate article structure with Claude
        uses: anthropics/claude-code-base-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          
          prompt: |
            健康・美容に関する記事の構成を作成してください。
            
            入力情報:
            - 記事タイトル: ${{ inputs.article_title }}
            - ターゲットペルソナ: ${{ inputs.target_persona }}
            - メタキーワード: ${{ inputs.meta_keywords }}
            
            タスク:
            1. 以下のファイルを読み込んで理解:
               - input_params.json: 入力パラメータ
               - phase1_output.json: 分析結果
               - phase2_research.json: リサーチ結果
            2. 分析とリサーチ結果を踏まえてペルソナに最適化された記事構成を作成
            3. 以下のファイルを生成:
               - 01_article_structure.md: 詳細な記事構成
               - 02_content_plan.md: 各セクションの内容計画
               - 03_seo_strategy.md: SEO戦略とキーワード配置計画
            
            要件:
            - ペルソナの悩みや関心事に寄り添う構成
            - メタキーワードを自然に組み込む
            - 薬機法・景表法を考慮した表現計画
            - 読みやすく価値のある記事構成
          
          allowed_tools: |
            Read,
            Write,
            Edit
          
          claude_env: |
            ARTICLE_ID=${{ needs.initialize.outputs.article_id }}
          
          max_turns: "10"

      - name: Upload structure artifacts
        uses: actions/upload-artifact@v4
        with:
          name: structure-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}
          retention-days: 30

  # ジョブ6: 記事本文の生成
  generate-content:
    needs: [initialize, generate-structure]
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 20
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-${{ needs.initialize.outputs.article_id }}'
          path: output/${{ needs.initialize.outputs.article_id }}
          merge-multiple: true

      - name: Generate article content with Claude
        uses: anthropics/claude-code-base-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          
          prompt: |
            記事本文を生成してください。
            
            タスク:
            1. 以下のファイルを読み込んで理解:
               - input_params.json: 入力パラメータ
               - phase1_output.json: 分析結果
               - phase2_research.json: リサーチ結果
               - 01_article_structure.md: 記事構成
               - 02_content_plan.md: 内容計画
               - 03_seo_strategy.md: SEO戦略
            
            2. ペルソナに最適化された記事本文を生成:
               - ペルソナの言葉遣いや関心事を反映
               - 具体的で実践的な内容
               - 読みやすい構成と自然な流れ
            
            3. 以下のファイルを生成:
               - 04_draft_article.md: Markdown形式の記事本文
               - 05_article.html: HTML形式の記事（適切なマークアップ）
               - 06_meta_data.json: メタ情報（タイトル、説明、キーワード等）
            
            要件:
            - 3000-5000文字程度
            - ペルソナに響く言葉選び
            - SEOを意識した見出し構成
            - 薬機法・景表法準拠
          
          allowed_tools: |
            Read,
            Write,
            Edit
          
          claude_env: |
            ARTICLE_ID=${{ needs.initialize.outputs.article_id }}
          
          max_turns: "15"

      - name: Upload content artifacts
        uses: actions/upload-artifact@v4
        with:
          name: content-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}
          retention-days: 30

  # ジョブ7: ファクトチェック
  factcheck:
    needs: [initialize, generate-content]
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-${{ needs.initialize.outputs.article_id }}'
          path: output/${{ needs.initialize.outputs.article_id }}
          merge-multiple: true

      - name: Fact-check article with Claude
        uses: anthropics/claude-code-base-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          
          prompt: |
            記事のファクトチェックを行ってください。
            
            タスク:
            1. 以下のファイルを読み込んで内容を確認:
               - 04_draft_article.md: 記事本文
               - phase2_research.json: リサーチ結果
            
            2. 以下の観点でチェック:
               - 事実の正確性（リサーチ結果との照合）
               - 薬機法・景表法の遵守
               - 数値や統計の正確性
               - 医学的・科学的主張の妥当性
            
            3. 修正が必要な場合:
               - 04_draft_article.md を直接編集
               - factcheck_report.md に修正内容を記録
            
            4. ペルソナへの配慮:
               - ペルソナが誤解しやすい表現の修正
               - より分かりやすい説明への改善
          
          allowed_tools: |
            View,
            Edit
          
          claude_env: |
            ARTICLE_ID=${{ needs.initialize.outputs.article_id }}
          
          max_turns: "10"

      - name: Upload factcheck artifacts
        uses: actions/upload-artifact@v4
        with:
          name: factcheck-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}
          retention-days: 30

  # ジョブ8: SEO最適化
  seo-optimization:
    needs: [initialize, generate-content]
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-${{ needs.initialize.outputs.article_id }}'
          path: output/${{ needs.initialize.outputs.article_id }}
          merge-multiple: true

      - name: SEO optimization with Claude
        uses: anthropics/claude-code-base-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          
          prompt: |
            記事のSEO最適化を行ってください。
            
            タスク:
            1. 以下のファイルを読み込んで最適化:
               - 04_draft_article.md: 記事本文
               - 05_article.html: HTML版記事
               - 03_seo_strategy.md: SEO戦略
               - input_params.json: メタキーワード確認
            
            2. SEO最適化の実施:
               - タイトルタグの最適化
               - メタディスクリプションの作成
               - 見出しタグ（H1-H3）の最適化
               - キーワード密度の調整（2-3%）
               - 内部リンク構造の提案
            
            3. ペルソナ向けSEO:
               - ペルソナが使う検索キーワードを意識
               - ペルソナの検索意図に合致する内容強化
            
            4. 生成ファイル:
               - 06_optimized_content.html: SEO最適化済みHTML
               - seo_optimization_report.md: 最適化内容レポート
          
          allowed_tools: |
            Read,
            Write,
            Edit
          
          claude_env: |
            ARTICLE_ID=${{ needs.initialize.outputs.article_id }}
          
          max_turns: "10"

      - name: Upload SEO artifacts
        uses: actions/upload-artifact@v4
        with:
          name: seo-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}
          retention-days: 30

  # ジョブ9: 画像生成（MCP + Imagen4）
  generate-images:
    if: ${{ inputs.enable_image_generation }}
    needs: [initialize, generate-structure]
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 20
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-${{ needs.initialize.outputs.article_id }}'
          path: output/${{ needs.initialize.outputs.article_id }}
          merge-multiple: true

      - name: Generate Images with Claude + MCP Imagen4
        uses: anthropics/claude-code-base-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          
          prompt: |
            記事に最適な画像を生成してください。
            
            タスク:
            1. 記事内容を理解:
               - input_params.json でペルソナを確認
               - 04_draft_article.md で記事内容を把握
               - 01_article_structure.md で構成を理解
            
            2. ペルソナに響く画像を生成:
               - ヒーロー画像（16:9）: 記事全体のイメージ
               - セクション画像（4:3）: 主要セクション用（3-4枚）
               
               重要: 最適化されたコンテンツ（06_optimized_content.html）を参照
            
            3. 画像生成の方針:
               - ペルソナの年代・性別に合わせたビジュアル
               - 清潔感と信頼感のあるデザイン
               - 記事内容と調和したカラーパレット
               - テキストやロゴは含まない
            
            4. MCPツールの使用:
               - mcp__gemini-imagen__list_models でモデル確認
               - mcp__gemini-imagen__generate_image で画像生成
               - imagen-4 または imagen-4-ultra を使用
            
            5. メタデータ作成:
               - images/metadata.json に生成情報を記録
               - 各画像のプロンプトと用途を記載
          
          mcp_config: |
            {
              "mcpServers": {
                "gemini-imagen": {
                  "command": "npx",
                  "args": [
                    "-y", 
                    "gemini-imagen-mcp-server",
                    "--model", "imagen-4"
                  ],
                  "env": {
                    "GEMINI_API_KEY": "${{ secrets.GEMINI_API_KEY }}"
                  }
                }
              }
            }
          
          allowed_tools: |
            Read,
            Write,
            mcp__gemini-imagen__generate_image,
            mcp__gemini-imagen__list_models
          
          claude_env: |
            ARTICLE_ID=${{ needs.initialize.outputs.article_id }}
          
          max_turns: "15"

      - name: Process generated images
        run: |
          ARTICLE_DIR="output/${{ needs.initialize.outputs.article_id }}"
          IMAGE_DIR="${ARTICLE_DIR}/images"
          
          # MCPサーバーは imagen/ ディレクトリに保存する
          if [ -d "imagen" ] && [ "$(ls -A imagen 2>/dev/null)" ]; then
            echo "✅ Images found in imagen directory:"
            ls -la imagen/
            
            # 画像を記事ディレクトリにコピー
            mkdir -p $IMAGE_DIR
            cp imagen/*.png $IMAGE_DIR/ 2>/dev/null || true
            cp imagen/*.jpg $IMAGE_DIR/ 2>/dev/null || true
            
            # リネーム（オプション）
            cd $IMAGE_DIR
            i=1
            for img in *.png *.jpg; do
              if [ -f "$img" ]; then
                if [ $i -eq 1 ]; then
                  mv "$img" "hero_image.png" 2>/dev/null || true
                else
                  mv "$img" "section_$((i-1))_image.png" 2>/dev/null || true
                fi
                i=$((i+1))
              fi
            done
            cd -
            
            echo "Final images:"
            ls -la $IMAGE_DIR
          else
            echo "⚠️ No images generated"
          fi

      - name: Upload image artifacts
        uses: actions/upload-artifact@v4
        with:
          name: images-${{ needs.initialize.outputs.article_id }}
          path: |
            output/${{ needs.initialize.outputs.article_id }}/images
            imagen/
          retention-days: 30

  # ジョブ10: 最終処理とアップロード
  finalize:
    needs: [initialize, analysis, research-merge, generate-structure, generate-content, factcheck, seo-optimization, generate-images]
    if: always()
    runs-on: ubuntu-latest
    environment: GA
    timeout-minutes: 10
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-${{ needs.initialize.outputs.article_id }}'
          path: output/${{ needs.initialize.outputs.article_id }}
          merge-multiple: true

      - name: Create final package with Claude
        uses: anthropics/claude-code-base-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          
          prompt: |
            記事の最終パッケージを作成してください。
            
            タスク:
            1. すべてのファイルを確認
            2. final_article.html を作成:
               - 記事本文（05_article.html）
               - 画像の適切な配置
               - メタ情報の統合
            3. summary.md を作成:
               - 生成された記事の概要
               - ペルソナへの最適化ポイント
               - SEO対策の実施内容
               - 使用画像のリスト
          
          allowed_tools: |
            Read,
            Write,
            Edit
          
          claude_env: |
            ARTICLE_ID=${{ needs.initialize.outputs.article_id }}
          
          max_turns: "10"

      # Google Drive Upload (オプション)
      - name: Setup Python for Drive upload
        if: ${{ inputs.enable_drive_upload }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies for Drive upload
        if: ${{ inputs.enable_drive_upload }}
        run: |
          pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client

      - name: Upload to Google Drive
        if: ${{ inputs.enable_drive_upload }}
        run: |
          python github-actions/scripts/upload_to_drive.py \
            --article-dir output/${{ needs.initialize.outputs.article_id }} \
            --drive-folder-id ${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}
        env:
          GOOGLE_DRIVE_CREDENTIALS: ${{ secrets.GOOGLE_DRIVE_CREDENTIALS }}

      - name: Create workflow summary
        if: always()
        run: |
          ARTICLE_DIR="output/${{ needs.initialize.outputs.article_id }}"
          
          echo "## 📝 Article Generation V3 Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📋 Input Parameters" >> $GITHUB_STEP_SUMMARY
          echo "- **Title**: ${{ inputs.article_title }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Persona**: ${{ inputs.target_persona }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Keywords**: ${{ inputs.meta_keywords }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$ARTICLE_DIR/summary.md" ]; then
            echo "### 📊 Generation Summary" >> $GITHUB_STEP_SUMMARY
            cat "$ARTICLE_DIR/summary.md" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📦 Generated Files" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          find $ARTICLE_DIR -type f -name "*.md" -o -name "*.html" -o -name "*.json" | sort >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          
          if [ -d "$ARTICLE_DIR/images" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🖼️ Generated Images" >> $GITHUB_STEP_SUMMARY
            echo "- Image count: $(find $ARTICLE_DIR/images -name "*.png" -o -name "*.jpg" | wc -l)" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload final package
        uses: actions/upload-artifact@v4
        with:
          name: final-article-${{ needs.initialize.outputs.article_id }}
          path: output/${{ needs.initialize.outputs.article_id }}
          retention-days: 30

  # 通知（オプション）
  notify:
    needs: [initialize, finalize]
    if: always() && vars.SLACK_WEBHOOK != ''
    runs-on: ubuntu-latest
    
    steps:
      - name: Send Slack notification
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        run: |
          STATUS="${{ needs.finalize.result }}"
          COLOR="good"
          EMOJI="✅"
          
          if [ "$STATUS" != "success" ]; then
            COLOR="danger"
            EMOJI="❌"
          fi
          
          curl -X POST $SLACK_WEBHOOK \
            -H 'Content-type: application/json' \
            -d '{
              "attachments": [{
                "color": "'$COLOR'",
                "title": "'$EMOJI' Article Generation V3 '$STATUS'",
                "fields": [
                  {"title": "Title", "value": "'"${{ inputs.article_title }}"'", "short": false},
                  {"title": "Persona", "value": "'"${{ inputs.target_persona }}"'", "short": false},
                  {"title": "Workflow", "value": "'"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"'", "short": false}
                ]
              }]
            }'